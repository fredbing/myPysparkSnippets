{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark read csv to DataFrame and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of using spark.read.csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Users/binggangliu/Downloads/WaterSites_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+----+---------------+-------+------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|                 _c0|              _c1| _c2|            _c3|    _c4|   _c5|       _c6|        _c7|                 _c8|                 _c9|                _c10|                _c11|                _c12|                _c13|                _c14|                _c15|                _c16|                _c17|                _c18|                _c19|                _c20|                _c21|                _c22|                _c23|                _c24|                _c25| _c26|\n",
      "+--------------------+-----------------+----+---------------+-------+------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|         Data Export|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "| Jun 2009 - May 2010|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|                null|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|1 - sorted by sit...|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|                null|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|High Water Usage ...|Water Stress Site|City|State/ Province|Country|Region|Latitude 1|Longitude 1|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|8C Delivered Sour...|8C Cargill Source...|8D Delivered Sour...|8D Surface Water ...|8D Ground Water S...|8E Cargill Direct...|8E Indirect Disch...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL WATER & WWT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|Notes|\n",
      "+--------------------+-----------------+----+---------------+-------+------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|         Data Export|              _c1|  _c2|            _c3|          _c4|          _c5|       _c6|        _c7|                 _c8|                 _c9|                _c10|                _c11|                _c12|                _c13|                _c14|                _c15|                _c16|                _c17|                _c18|                _c19|                _c20|                _c21|                _c22|                _c23|                _c24|                _c25| _c26|\n",
      "+--------------------+-----------------+-----+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "| Jun 2009 - May 2010|             null| null|           null|         null|         null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|                null|             null| null|           null|         null|         null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|1 - sorted by sit...|             null| null|           null|         null|         null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|                null|             null| null|           null|         null|         null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|High Water Usage ...|Water Stress Site| City|State/ Province|      Country|       Region|Latitude 1|Longitude 1|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|8C Delivered Sour...|8C Cargill Source...|8D Delivered Sour...|8D Surface Water ...|8D Ground Water S...|8E Cargill Direct...|8E Indirect Disch...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL WATER & WWT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|Notes|\n",
      "|                 Yes|              Yes|Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|             688,905|                   0|                   0|                   0|                   0|                   0|                   0|                   0|             560,434|                   0|             688,905|             688,905|             228,801|                   0|           1,249,339|               1,887|              30,384| null|\n",
      "+--------------------+-----------------+-----+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql.types import *\n",
    "df = spark.read.csv(\"/Users/binggangliu/Downloads/WaterSites_info.csv\", inferSchema = True, header = True)\n",
    "df.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### inferSchema = True, will let Spark automatically infer the data type for each column when reading the csv file;  header = True, will let Spark set the first line of file to be used to name the columns and not include it in the data. (For the case in this example, it does not seem to matter with these two options being set as True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Data Export: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  There are a few rows having null values in all columns that need to be skipped. Below first try to generate a column with unique IDs, then find out the rows that need to be filtered out and their cooresponding IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------+\n",
      "|          _c4|\n",
      "+-------------+\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|      Country|\n",
      "|United States|\n",
      "|United States|\n",
      "|United States|\n",
      "|        China|\n",
      "|      Germany|\n",
      "+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "#df.withColumn(\"Index\", monotonically_increasing_id().alias('id')).filter(id > 2).drop(\"Index\")\n",
    "df.select(monotonically_increasing_id().alias('id')).show(10)\n",
    "df.select('_c4').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  It looks there are 4 empty rows that need to be filtered out. Below, add a new ID column using withColumn() then filter out the empty rows using the ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df.withColumn('ID', monotonically_increasing_id().alias('ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_filter = df_id.filter(df_id.ID > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+---+\n",
      "|         Data Export|              _c1|    _c2|            _c3|          _c4|          _c5|       _c6|        _c7|                 _c8|                 _c9|                _c10|                _c11|                _c12|                _c13|                _c14|                _c15|                _c16|                _c17|                _c18|                _c19|                _c20|                _c21|                _c22|                _c23|                _c24|                _c25| _c26| ID|\n",
      "+--------------------+-----------------+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+---+\n",
      "|High Water Usage ...|Water Stress Site|   City|State/ Province|      Country|       Region|Latitude 1|Longitude 1|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|8C Delivered Sour...|8C Cargill Source...|8D Delivered Sour...|8D Surface Water ...|8D Ground Water S...|8E Cargill Direct...|8E Indirect Disch...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL WATER & WWT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|Notes|  4|\n",
      "|                 Yes|              Yes|  Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|             688,905|                   0|                   0|                   0|                   0|                   0|                   0|                   0|             560,434|                   0|             688,905|             688,905|             228,801|                   0|           1,249,339|               1,887|              30,384| null|  5|\n",
      "|                 Yes|              Yes|  Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|           9,488,173|                   0|                   0|                   0|                   0|                   0|                   0|                   0|           6,007,131|                   0|           9,488,173|           9,488,173|           3,798,880|                   0|          15,495,304|              25,995|                null| null|  6|\n",
      "|                 Yes|              Yes|Memphis|             TN|United States|NORTH AMERICA|        35|        -90|                   0|           7,037,363|                   0|                   0|                   0|                   0|                   0|                   0|           1,174,407|                   0|           6,740,902|           7,037,363|           7,037,363|           1,659,561|                   0|          14,952,673|              19,280|                null| null|  7|\n",
      "+--------------------+-----------------+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+---+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_id_filter.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Now it is time to remove the columns that are not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Export',\n",
       " '_c1',\n",
       " '_c2',\n",
       " '_c3',\n",
       " '_c4',\n",
       " '_c5',\n",
       " '_c6',\n",
       " '_c7',\n",
       " '_c8',\n",
       " '_c9',\n",
       " '_c10',\n",
       " '_c11',\n",
       " '_c12',\n",
       " '_c13',\n",
       " '_c14',\n",
       " '_c15',\n",
       " '_c16',\n",
       " '_c17',\n",
       " '_c18',\n",
       " '_c19',\n",
       " '_c20',\n",
       " '_c21',\n",
       " '_c22',\n",
       " '_c23',\n",
       " '_c24',\n",
       " '_c25',\n",
       " '_c26',\n",
       " 'ID']"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id_filter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_id_filter.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop the unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd = df_id_filter.drop('Data Export', '_c1', '_c12', '_c13', '_c14', '_c15', '_c16', '_c17', '_c18', '_c19', '_c20', '_c21', '_c22', '_c23', '_c24','_c25', '_c26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|     _c2|            _c3|          _c4|          _c5|       _c6|        _c7|                 _c8|                 _c9|                _c10|                _c11| ID|\n",
      "+--------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|    City|State/ Province|      Country|       Region|Latitude 1|Longitude 1|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|  4|\n",
      "|   Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|             688,905|                   0|                   0|  5|\n",
      "|   Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|           9,488,173|                   0|                   0|  6|\n",
      "| Memphis|             TN|United States|NORTH AMERICA|        35|        -90|                   0|           7,037,363|                   0|                   0|  7|\n",
      "|Songyuan|          Jilin|        China| ASIA/PACIFIC|        45|        125|                   0|           3,315,709|                   0|                   0|  8|\n",
      "| Krefeld|        GERMANY|      Germany|       EUROPE|        51|          7|                   0|              13,295|                   0|           2,901,482|  9|\n",
      "+--------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfd.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rename the automatated generated header columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dfd.withColumnRenamed('_c2', 'City').withColumnRenamed('_c3', 'State').withColumnRenamed('_c4', 'Country').withColumnRenamed('_c5', 'Region').withColumnRenamed('_c6', 'Latitude').withColumnRenamed('_c7', 'Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|    City|          State|      Country|       Region|  Latitude|  Longitude|                 _c8|                 _c9|                _c10|                _c11| ID|\n",
      "+--------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|    City|State/ Province|      Country|       Region|Latitude 1|Longitude 1|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|  4|\n",
      "|   Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|             688,905|                   0|                   0|  5|\n",
      "|   Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|           9,488,173|                   0|                   0|  6|\n",
      "| Memphis|             TN|United States|NORTH AMERICA|        35|        -90|                   0|           7,037,363|                   0|                   0|  7|\n",
      "|Songyuan|          Jilin|        China| ASIA/PACIFIC|        45|        125|                   0|           3,315,709|                   0|                   0|  8|\n",
      "+--------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- ID: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the commas in the number strings for columns '_c8' to '_c11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "dff = dff.withColumn('_c8', regexp_replace('_c8', ',', ''))\n",
    "dff = dff.withColumn('_c9', regexp_replace('_c9', ',', ''))\n",
    "dff = dff.withColumn('_c10', regexp_replace('_c10', ',', ''))\n",
    "dff = dff.withColumn('_c11', regexp_replace('_c11', ',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 _c8|                 _c9|                _c10|                _c11|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|\n",
      "|                   0|              688905|                   0|                   0|\n",
      "|                   0|             9488173|                   0|                   0|\n",
      "|                   0|             7037363|                   0|                   0|\n",
      "|                   0|             3315709|                   0|                   0|\n",
      "|                   0|               13295|                   0|             2901482|\n",
      "|                   0|               22685|                   0|             2653627|\n",
      "|                   0|             1575256|                   0|              788616|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.select('_c8', '_c9', '_c10', '_c11').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the number strings to float data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.withColumn('_c8', dff._c8.cast(FloatType()))\n",
    "dff = dff.withColumn('_c9', dff._c9.cast(FloatType()))\n",
    "dff = dff.withColumn('_c10', dff._c10.cast(FloatType()))\n",
    "dff = dff.withColumn('_c11', dff._c11.cast(FloatType()))\n",
    "\n",
    "dff = dff.withColumn('Latitude', dff.Latitude.cast(FloatType()))\n",
    "dff = dff.withColumn('Longitude', dff.Longitude.cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Latitude: float (nullable = true)\n",
      " |-- Longitude: float (nullable = true)\n",
      " |-- _c8: float (nullable = true)\n",
      " |-- _c9: float (nullable = true)\n",
      " |-- _c10: float (nullable = true)\n",
      " |-- _c11: float (nullable = true)\n",
      " |-- ID: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### columns '_c8' and '_c9' need to be added together and renamed, same thing for columns '_c10' and '_c11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import sum\n",
    "dff_sum = dff.withColumn('Delivered', dff._c8 + dff._c9).withColumn('Surface', dff._c10 + dff._c11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Latitude: float (nullable = true)\n",
      " |-- Longitude: float (nullable = true)\n",
      " |-- _c8: float (nullable = true)\n",
      " |-- _c9: float (nullable = true)\n",
      " |-- _c10: float (nullable = true)\n",
      " |-- _c11: float (nullable = true)\n",
      " |-- ID: long (nullable = false)\n",
      " |-- Delivered: float (nullable = true)\n",
      " |-- Surface: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff_sum.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+-------------+--------+---------+----+---------+----+----+---+---------+-------+\n",
      "|    City|          State|      Country|       Region|Latitude|Longitude| _c8|      _c9|_c10|_c11| ID|Delivered|Surface|\n",
      "+--------+---------------+-------------+-------------+--------+---------+----+---------+----+----+---+---------+-------+\n",
      "|    City|State/ Province|      Country|       Region|    null|     null|null|     null|null|null|  4|     null|   null|\n",
      "|   Blair|             NE|United States|NORTH AMERICA|    42.0|    -96.0| 0.0| 688905.0| 0.0| 0.0|  5| 688905.0|    0.0|\n",
      "|   Blair|             NE|United States|NORTH AMERICA|    42.0|    -96.0| 0.0|9488173.0| 0.0| 0.0|  6|9488173.0|    0.0|\n",
      "| Memphis|             TN|United States|NORTH AMERICA|    35.0|    -90.0| 0.0|7037363.0| 0.0| 0.0|  7|7037363.0|    0.0|\n",
      "|Songyuan|          Jilin|        China| ASIA/PACIFIC|    45.0|    125.0| 0.0|3315709.0| 0.0| 0.0|  8|3315709.0|    0.0|\n",
      "+--------+---------------+-------------+-------------+--------+---------+----+---------+----+----+---+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff_sum.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now columns '_c8', '_c9', '_c10', '_c11' need to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff2 = dff_sum.drop('_c8', '_c9', '_c10', '_c11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+-------------+--------+---------+---+---------+---------+\n",
      "|       City|          State|      Country|       Region|Latitude|Longitude| ID|Delivered|  Surface|\n",
      "+-----------+---------------+-------------+-------------+--------+---------+---+---------+---------+\n",
      "|       City|State/ Province|      Country|       Region|    null|     null|  4|     null|     null|\n",
      "|      Blair|             NE|United States|NORTH AMERICA|    42.0|    -96.0|  5| 688905.0|      0.0|\n",
      "|      Blair|             NE|United States|NORTH AMERICA|    42.0|    -96.0|  6|9488173.0|      0.0|\n",
      "|    Memphis|             TN|United States|NORTH AMERICA|    35.0|    -90.0|  7|7037363.0|      0.0|\n",
      "|   Songyuan|          Jilin|        China| ASIA/PACIFIC|    45.0|    125.0|  8|3315709.0|      0.0|\n",
      "|    Krefeld|        GERMANY|      Germany|       EUROPE|    51.0|      7.0|  9|  13295.0|2901482.0|\n",
      "|Castelmassa|          ITALY|        Italy|       EUROPE|    45.0|     11.0| 10|  22685.0|2653627.0|\n",
      "+-----------+---------------+-------------+-------------+--------+---------+---+---------+---------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff2.show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Remove the original csv header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff3 = dff2.filter(dff2.ID != 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------+-------------+--------+---------+---+---------+---------+\n",
      "|        City|      State|       Country|       Region|Latitude|Longitude| ID|Delivered|  Surface|\n",
      "+------------+-----------+--------------+-------------+--------+---------+---+---------+---------+\n",
      "|       Blair|         NE| United States|NORTH AMERICA|    42.0|    -96.0|  5| 688905.0|      0.0|\n",
      "|       Blair|         NE| United States|NORTH AMERICA|    42.0|    -96.0|  6|9488173.0|      0.0|\n",
      "|     Memphis|         TN| United States|NORTH AMERICA|    35.0|    -90.0|  7|7037363.0|      0.0|\n",
      "|    Songyuan|      Jilin|         China| ASIA/PACIFIC|    45.0|    125.0|  8|3315709.0|      0.0|\n",
      "|     Krefeld|    GERMANY|       Germany|       EUROPE|    51.0|      7.0|  9|  13295.0|2901482.0|\n",
      "| Castelmassa|      ITALY|         Italy|       EUROPE|    45.0|     11.0| 10|  22685.0|2653627.0|\n",
      "|  Manchester|    ENGLAND|United Kingdom|       EUROPE|    53.0|     -2.0| 11|1575256.0| 788616.0|\n",
      "|Sas van Gent|NETHERLANDS|   Netherlands|       EUROPE|    51.0|      4.0| 12|2358100.0|      0.0|\n",
      "|  Fort Morga|         CO| United States|NORTH AMERICA|    40.0|   -104.0| 13|2142050.0|      0.0|\n",
      "|     Hammond|         IN| United States|NORTH AMERICA|    42.0|    -88.0| 14| 375228.0|1751402.0|\n",
      "+------------+-----------+--------------+-------------+--------+---------+---+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff3 = dff3.drop('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------+-------------+--------+---------+---------+---------+\n",
      "|        City|      State|       Country|       Region|Latitude|Longitude|Delivered|  Surface|\n",
      "+------------+-----------+--------------+-------------+--------+---------+---------+---------+\n",
      "|       Blair|         NE| United States|NORTH AMERICA|    42.0|    -96.0| 688905.0|      0.0|\n",
      "|       Blair|         NE| United States|NORTH AMERICA|    42.0|    -96.0|9488173.0|      0.0|\n",
      "|     Memphis|         TN| United States|NORTH AMERICA|    35.0|    -90.0|7037363.0|      0.0|\n",
      "|    Songyuan|      Jilin|         China| ASIA/PACIFIC|    45.0|    125.0|3315709.0|      0.0|\n",
      "|     Krefeld|    GERMANY|       Germany|       EUROPE|    51.0|      7.0|  13295.0|2901482.0|\n",
      "| Castelmassa|      ITALY|         Italy|       EUROPE|    45.0|     11.0|  22685.0|2653627.0|\n",
      "|  Manchester|    ENGLAND|United Kingdom|       EUROPE|    53.0|     -2.0|1575256.0| 788616.0|\n",
      "|Sas van Gent|NETHERLANDS|   Netherlands|       EUROPE|    51.0|      4.0|2358100.0|      0.0|\n",
      "|  Fort Morga|         CO| United States|NORTH AMERICA|    40.0|   -104.0|2142050.0|      0.0|\n",
      "|     Hammond|         IN| United States|NORTH AMERICA|    42.0|    -88.0| 375228.0|1751402.0|\n",
      "+------------+-----------+--------------+-------------+--------+---------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         Delivered|\n",
      "+-------+------------------+\n",
      "|  count|               141|\n",
      "|   mean| 463472.3475177305|\n",
      "| stddev|1235078.1644725103|\n",
      "|    min|               0.0|\n",
      "|    max|         9488173.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff3.describe('Delivered').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the cities with top 'Delivered' values and top 'Surface' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, desc\n",
    "Delivered_desc = dff3.select('City', 'State', 'Country', 'Delivered').sort(desc('Delivered'))\n",
    "Surface_desc = dff3.select('City', 'State', 'Country', 'Surface').sort(desc('Surface'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------+---------+\n",
      "|        City|      State|       Country|Delivered|\n",
      "+------------+-----------+--------------+---------+\n",
      "|       Blair|         NE| United States|9488173.0|\n",
      "|     Memphis|         TN| United States|7037363.0|\n",
      "|      Dayton|         OH| United States|6188027.0|\n",
      "|    Songyuan|      Jilin|         China|3315709.0|\n",
      "|Cedar Rapids|         IA| United States|3056426.0|\n",
      "|  Wapello Co|         IA| United States|2381374.0|\n",
      "|Sas van Gent|NETHERLANDS|   Netherlands|2358100.0|\n",
      "|  High River|         AB|        Canada|2281672.0|\n",
      "|  Fort Morga|         CO| United States|2142050.0|\n",
      "|      Dayton|         VA| United States|1661939.0|\n",
      "|  Springdale|         AR| United States|1577397.0|\n",
      "|  Manchester|    ENGLAND|United Kingdom|1575256.0|\n",
      "|       Barby|    GERMANY|       Germany|1543247.0|\n",
      "|   Plainview|         TX| United States|1505837.0|\n",
      "|    Bielany |     POLAND|        Poland|1308366.0|\n",
      "|      Bergen|NETHERLANDS|   Netherlands|1246625.0|\n",
      "|  California|         MO| United States|1050982.0|\n",
      "|      Biggar|         SK|        Canada| 913329.0|\n",
      "|      Guelph|         ON|        Canada| 846943.0|\n",
      "|  Haubourdin|     FRANCE|        France| 769829.0|\n",
      "+------------+-----------+--------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Delivered_desc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------+---------+\n",
      "|                City|       State|      Country|  Surface|\n",
      "+--------------------+------------+-------------+---------+\n",
      "|           Eddyville|          IA|United States|7047098.0|\n",
      "|          Spiritwood|          ND|United States|3262601.0|\n",
      "|             Krefeld|     GERMANY|      Germany|2901482.0|\n",
      "|              Franca|      BRAZIL|       Brazil|2717358.0|\n",
      "|         Castelmassa|       ITALY|        Italy|2653627.0|\n",
      "|            Wahpeton|          ND|United States|2538523.0|\n",
      "|          Dodge City|          KS|United States|2517785.0|\n",
      "|            Schuyler|          NE|United States|2505549.0|\n",
      "|          Beardstown|          IL|United States|2199964.0|\n",
      "|              Friona|          TX|United States|2033228.0|\n",
      "|             Hammond|          IN|United States|1751402.0|\n",
      "|Martorell/Sante D...|       SPAIN|        Spain|1710833.0|\n",
      "|             Efremov|      RUSSIA|       Russia|1495168.0|\n",
      "|           Eddyville|          IA|United States|1459968.0|\n",
      "|              Bernal|Buenos Aires|    Argentina|1332304.0|\n",
      "|               Leoti|          KS|United States|1208944.0|\n",
      "|            Santa Fe|    Santa Fe|    Argentina|1166568.0|\n",
      "|              Izegem|     BELGIUM|      Belgium|1126547.0|\n",
      "|             Dalhart|          TX|United States|1102958.0|\n",
      "|                 PP2|    THAILAND|     Thailand|1034520.0|\n",
      "+--------------------+------------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Surface_desc.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of using sqlContext.read.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and load csv file with sqlContext.read.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = sqlContext.read.load(\"/Users/binggangliu/Downloads/CalEvent.csv\",\n",
    "                           format = 'com.databricks.spark.csv',\n",
    "                           header = 'true',\n",
    "                           inferSchema = 'true',\n",
    "                           nullValue = 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Start Date : string (nullable = true)\n",
      " |-- Start Time: string (nullable = true)\n",
      " |-- End Date: string (nullable = true)\n",
      " |-- End Time: string (nullable = true)\n",
      " |-- Event Title : string (nullable = true)\n",
      " |-- All Day Event: string (nullable = true)\n",
      " |-- No End Time: string (nullable = true)\n",
      " |-- Event Description: string (nullable = true)\n",
      " |-- Contact : string (nullable = true)\n",
      " |-- Contact Email: string (nullable = true)\n",
      " |-- Contact Phone: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Category: integer (nullable = true)\n",
      " |-- Mandatory: string (nullable = true)\n",
      " |-- Registration: string (nullable = true)\n",
      " |-- Maximum: integer (nullable = true)\n",
      " |-- Last Date To Register: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.withColumnRenamed('Last Date To Register', 'DeadEnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Start Date : string (nullable = true)\n",
      " |-- Start Time: string (nullable = true)\n",
      " |-- End Date: string (nullable = true)\n",
      " |-- End Time: string (nullable = true)\n",
      " |-- Event Title : string (nullable = true)\n",
      " |-- All Day Event: string (nullable = true)\n",
      " |-- No End Time: string (nullable = true)\n",
      " |-- Event Description: string (nullable = true)\n",
      " |-- Contact : string (nullable = true)\n",
      " |-- Contact Email: string (nullable = true)\n",
      " |-- Contact Phone: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Category: integer (nullable = true)\n",
      " |-- Mandatory: string (nullable = true)\n",
      " |-- Registration: string (nullable = true)\n",
      " |-- Maximum: integer (nullable = true)\n",
      " |-- DeadEnd: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|DeadEnd|\n",
      "+-------+\n",
      "| 9/2/11|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df3.select(\"DeadEnd\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|Start Date |        Event Title |\n",
      "+-----------+--------------------+\n",
      "|     9/5/11|Social Studies De...|\n",
      "|     9/5/11|  Curriculum Meeting|\n",
      "+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df3.select('Start Date ', 'Event Title ').distinct().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
