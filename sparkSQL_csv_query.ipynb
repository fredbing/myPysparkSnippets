{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark SQL for csv data querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2 = sqlContext.read.load(\"/Users/binggangliu/Downloads/WaterSites_info.csv\",\n",
    "                           format = 'com.databricks.spark.csv',\n",
    "                           header = 'true', # use first line of file as header\n",
    "                           inferSchema = 'true', # automatically infer data types\n",
    "                           nullValue = 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.withColumnRenamed('Data Export', '_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|         New Site/No|\n",
      "|High Water Usage ...|\n",
      "|Yes as part of co...|\n",
      "|                null|\n",
      "|                  No|\n",
      "|                 Yes|\n",
      "| Jun 2009 - May 2010|\n",
      "|1 - sorted by sit...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(\"_c0\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+----+---------------+-------+------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|                 _c0|              _c1| _c2|            _c3|    _c4|   _c5|       _c6|        _c7|                 _c8|                 _c9|                _c10|                _c11|                _c12|                _c13|                _c14|                _c15|                _c16|                _c17|                _c18|                _c19|                _c20|                _c21|                _c22|                _c23|                _c24|                _c25| _c26|\n",
      "+--------------------+-----------------+----+---------------+-------+------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "| Jun 2009 - May 2010|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|                null|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|1 - sorted by sit...|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|                null|             null|null|           null|   null|  null|      null|       null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null| null|\n",
      "|High Water Usage ...|Water Stress Site|City|State/ Province|Country|Region|Latitude 1|Longitude 1|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|8C Delivered Sour...|8C Cargill Source...|8D Delivered Sour...|8D Surface Water ...|8D Ground Water S...|8E Cargill Direct...|8E Indirect Disch...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL WATER & WWT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|Notes|\n",
      "+--------------------+-----------------+----+---------------+-------+------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|          _c4|\n",
      "+-------------+\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|      Country|\n",
      "|United States|\n",
      "|United States|\n",
      "|United States|\n",
      "|        China|\n",
      "|      Germany|\n",
      "+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "#df3.select(monotonically_increasing_id().alias('id')).show(10)\n",
    "df3.select('_c4').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+---+\n",
      "|                 _c0|              _c1|    _c2|            _c3|          _c4|          _c5|       _c6|        _c7|                 _c8|                 _c9|                _c10|                _c11|                _c12|                _c13|                _c14|                _c15|                _c16|                _c17|                _c18|                _c19|                _c20|                _c21|                _c22|                _c23|                _c24|                _c25| _c26| ID|\n",
      "+--------------------+-----------------+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+---+\n",
      "|High Water Usage ...|Water Stress Site|   City|State/ Province|      Country|       Region|Latitude 1|Longitude 1|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|8C Delivered Sour...|8C Cargill Source...|8D Delivered Sour...|8D Surface Water ...|8D Ground Water S...|8E Cargill Direct...|8E Indirect Disch...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|TOTAL WATER & WWT...|TOTAL PROCESS WAT...|TOTAL PROCESS WAT...|Notes|  4|\n",
      "|                 Yes|              Yes|  Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|             688,905|                   0|                   0|                   0|                   0|                   0|                   0|                   0|             560,434|                   0|             688,905|             688,905|             228,801|                   0|           1,249,339|               1,887|              30,384| null|  5|\n",
      "|                 Yes|              Yes|  Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|           9,488,173|                   0|                   0|                   0|                   0|                   0|                   0|                   0|           6,007,131|                   0|           9,488,173|           9,488,173|           3,798,880|                   0|          15,495,304|              25,995|                null| null|  6|\n",
      "|                 Yes|              Yes|Memphis|             TN|United States|NORTH AMERICA|        35|        -90|                   0|           7,037,363|                   0|                   0|                   0|                   0|                   0|                   0|           1,174,407|                   0|           6,740,902|           7,037,363|           7,037,363|           1,659,561|                   0|          14,952,673|              19,280|                null| null|  7|\n",
      "+--------------------+-----------------+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+---+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df3.withColumn('ID', monotonically_increasing_id().alias('ID'))\n",
    "df3 = df3.filter(df3.ID > 3)\n",
    "df3.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop('_c0', '_c1', '_c12', '_c13', '_c14', '_c15', '_c16', '_c17', '_c18', '_c19', '_c20', '_c21', '_c22', '_c23', '_c24','_c25', '_c26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|    _c2|            _c3|          _c4|          _c5|       _c6|        _c7|                 _c8|                 _c9|                _c10|                _c11| ID|\n",
      "+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|   City|State/ Province|      Country|       Region|Latitude 1|Longitude 1|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|  4|\n",
      "|  Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|             688,905|                   0|                   0|  5|\n",
      "|  Blair|             NE|United States|NORTH AMERICA|        42|        -96|                   0|           9,488,173|                   0|                   0|  6|\n",
      "|Memphis|             TN|United States|NORTH AMERICA|        35|        -90|                   0|           7,037,363|                   0|                   0|  7|\n",
      "+-------+---------------+-------------+-------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+---+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df4 = df4.withColumn('_c8', regexp_replace('_c8', ',', ''))\n",
    "df4 = df4.withColumn('_c9', regexp_replace('_c9', ',', ''))\n",
    "df4 = df4.withColumn('_c10', regexp_replace('_c10', ',', ''))\n",
    "df4 = df4.withColumn('_c11', regexp_replace('_c11', ',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 _c8|                 _c9|                _c10|                _c11|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|8A Delivered Sour...|8B Delivered Sour...|8B Surface and Ra...|8B Ground Water S...|\n",
      "|                   0|              688905|                   0|                   0|\n",
      "|                   0|             9488173|                   0|                   0|\n",
      "|                   0|             7037363|                   0|                   0|\n",
      "|                   0|             3315709|                   0|                   0|\n",
      "|                   0|               13295|                   0|             2901482|\n",
      "|                   0|               22685|                   0|             2653627|\n",
      "|                   0|             1575256|                   0|              788616|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select('_c8', '_c9', '_c10', '_c11').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "df4 = df4.withColumn('_c6', df4._c6.cast(FloatType()))\n",
    "df4 = df4.withColumn('_c7', df4._c7.cast(FloatType()))\n",
    "\n",
    "df4 = df4.withColumn('_c8', df4._c8.cast(FloatType()))\n",
    "df4 = df4.withColumn('_c9', df4._c9.cast(FloatType()))\n",
    "df4 = df4.withColumn('_c10', df4._c10.cast(FloatType()))\n",
    "df4 = df4.withColumn('_c11', df4._c11.cast(FloatType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: float (nullable = true)\n",
      " |-- _c7: float (nullable = true)\n",
      " |-- _c8: float (nullable = true)\n",
      " |-- _c9: float (nullable = true)\n",
      " |-- _c10: float (nullable = true)\n",
      " |-- _c11: float (nullable = true)\n",
      " |-- ID: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = (df4.withColumnRenamed('_c2', 'City').withColumnRenamed('_c3', 'State').withColumnRenamed('_c4', 'Country')\n",
    "       .withColumnRenamed('_c5', 'Region').withColumnRenamed('_c6', 'Latitude').withColumnRenamed('_c7', 'Longitude')\n",
    "       .withColumnRenamed('_c8', 'Delivered_A').withColumnRenamed('_c9', 'Delivered_B')\n",
    "       .withColumnRenamed('_c10', 'Surface_A').withColumnRenamed('_c11', 'Surface_B')\n",
    "      )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+-------------+--------+---------+-----------+-----------+---------+---------+---+\n",
      "|    City|          State|      Country|       Region|Latitude|Longitude|Delivered_A|Delivered_B|Surface_A|Surface_B| ID|\n",
      "+--------+---------------+-------------+-------------+--------+---------+-----------+-----------+---------+---------+---+\n",
      "|    City|State/ Province|      Country|       Region|    null|     null|       null|       null|     null|     null|  4|\n",
      "|   Blair|             NE|United States|NORTH AMERICA|    42.0|    -96.0|        0.0|   688905.0|      0.0|      0.0|  5|\n",
      "|   Blair|             NE|United States|NORTH AMERICA|    42.0|    -96.0|        0.0|  9488173.0|      0.0|      0.0|  6|\n",
      "| Memphis|             TN|United States|NORTH AMERICA|    35.0|    -90.0|        0.0|  7037363.0|      0.0|      0.0|  7|\n",
      "|Songyuan|          Jilin|        China| ASIA/PACIFIC|    45.0|    125.0|        0.0|  3315709.0|      0.0|      0.0|  8|\n",
      "| Krefeld|        GERMANY|      Germany|       EUROPE|    51.0|      7.0|        0.0|    13295.0|      0.0|2901482.0|  9|\n",
      "+--------+---------------+-------------+-------------+--------+---------+-----------+-----------+---------+---------+---+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.filter(df5.ID != 4)\n",
    "df6 = df5.drop('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------+-------------+--------+---------+-----------+-----------+---------+---------+\n",
      "|    City|  State|      Country|       Region|Latitude|Longitude|Delivered_A|Delivered_B|Surface_A|Surface_B|\n",
      "+--------+-------+-------------+-------------+--------+---------+-----------+-----------+---------+---------+\n",
      "|   Blair|     NE|United States|NORTH AMERICA|    42.0|    -96.0|        0.0|   688905.0|      0.0|      0.0|\n",
      "|   Blair|     NE|United States|NORTH AMERICA|    42.0|    -96.0|        0.0|  9488173.0|      0.0|      0.0|\n",
      "| Memphis|     TN|United States|NORTH AMERICA|    35.0|    -90.0|        0.0|  7037363.0|      0.0|      0.0|\n",
      "|Songyuan|  Jilin|        China| ASIA/PACIFIC|    45.0|    125.0|        0.0|  3315709.0|      0.0|      0.0|\n",
      "| Krefeld|GERMANY|      Germany|       EUROPE|    51.0|      7.0|        0.0|    13295.0|      0.0|2901482.0|\n",
      "+--------+-------+-------------+-------------+--------+---------+-----------+-----------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.registerTempTable(\"WaterInfo\")\n",
    "Countries = sqlContext.sql(\"select distinct Country, count(Country) as cnt from WaterInfo group by Country order by cnt desc\")\n",
    "States = sqlContext.sql(\"select distinct State, count(State) as snt from WaterInfo group by State order by snt desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+\n",
      "|       Country|cnt|\n",
      "+--------------+---+\n",
      "| United States| 37|\n",
      "|         China| 11|\n",
      "|       Belgium| 10|\n",
      "|United Kingdom| 10|\n",
      "|   Netherlands| 10|\n",
      "|        Brazil|  9|\n",
      "|       Germany|  7|\n",
      "|        Canada|  6|\n",
      "|     Argentina|  5|\n",
      "|        Russia|  5|\n",
      "|         Spain|  5|\n",
      "|     Australia|  4|\n",
      "|      Thailand|  3|\n",
      "|         India|  3|\n",
      "|        France|  2|\n",
      "|      Malaysia|  2|\n",
      "|        Poland|  1|\n",
      "|     Venezuela|  1|\n",
      "|         Italy|  1|\n",
      "|       Ukraine|  1|\n",
      "+--------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Countries.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+\n",
      "|         State|snt|\n",
      "+--------------+---+\n",
      "|   NETHERLANDS| 10|\n",
      "|       BELGIUM|  9|\n",
      "|             0|  7|\n",
      "|       ENGLAND|  6|\n",
      "|            TX|  6|\n",
      "|  Minas Gerais|  5|\n",
      "|            IA|  5|\n",
      "|        RUSSIA|  5|\n",
      "|       GERMANY|  5|\n",
      "|            MO|  4|\n",
      "|         SPAIN|  4|\n",
      "|UNITED KINGDOM|  4|\n",
      "|      THAILAND|  3|\n",
      "|        BRAZIL|  3|\n",
      "|            TN|  3|\n",
      "|      Santa Fe|  3|\n",
      "|            NE|  3|\n",
      "|         India|  2|\n",
      "|            SK|  2|\n",
      "|     Guangdong|  2|\n",
      "+--------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "States.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_Delivered = sqlContext.sql(\"select City, Delivered_A, Delivered_B from WaterInfo where Country = 'Germany' order by City\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------+\n",
      "|   City|Delivered_A|Delivered_B|\n",
      "+-------+-----------+-----------+\n",
      "|  Barby|        0.0|  1543247.0|\n",
      "|Krefeld|        0.0|    13295.0|\n",
      "|  Mainz|        0.0|     7573.0|\n",
      "|  Mainz|        0.0|      406.0|\n",
      "|  Riesa|        0.0|     2628.0|\n",
      "|  Riesa|        0.0|      919.0|\n",
      "|  Riesa|        0.0|      679.0|\n",
      "+-------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Germany_Delivered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Belgium_Surface = sqlContext.sql(\"select City, Surface_A, Surface_B from WaterInfo where Country = 'Belgium' order by City\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+\n",
      "|   City|Surface_A|Surface_B|\n",
      "+-------+---------+---------+\n",
      "|Antwerp|      0.0|      0.0|\n",
      "|Antwerp|      0.0|      0.0|\n",
      "|Antwerp|      0.0|      0.0|\n",
      "|  Ghent|      0.0|      0.0|\n",
      "|  Ghent|      0.0|      0.0|\n",
      "|  Ghent|      0.0|      0.0|\n",
      "|  Ghent|      0.0|      0.0|\n",
      "| Herent|      0.0| 523690.0|\n",
      "| Izegem|1126547.0|      0.0|\n",
      "| Izegem|      0.0|      0.0|\n",
      "+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Belgium_Surface.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
